# Copyright (C) 2024-2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

apiVersion: gmc.opea.io/v1alpha3
kind: GMConnector
metadata:
  labels:
    app.kubernetes.io/name: gmconnector
    app.kubernetes.io/managed-by: kustomize
    gmc/platform: xeon
  name: chatqa
  namespace: chatqa
spec:
  routerConfig:
    name: router
    serviceName: router-service
  nodes:
    root:
      routerType: Sequence
      steps:
      - name: Fingerprint
        internalService:
          serviceName: fgp-svc
          config:
            endpoint: /v1/system_fingerprint/append_arguments
      - name: Embedding
        data: $response
        dependency: Hard
        internalService:
          serviceName: embedding-svc
          config:
            endpoint: /v1/embeddings
            EMBEDDING_MODEL_SERVER_ENDPOINT: torchserve-embedding-svc
            EMBEDDING_MODEL_NAME: "sentence-transformers/distiluse-base-multilingual-cased-v1"
            EMBEDDING_MODEL_SERVER: "torchserve"
            EMBEDDING_CONNECTOR: "langchain"
      - name: TorchserveEmbedding
        internalService:
          serviceName: torchserve-embedding-svc
          config:
            TORCHSERVE_MODEL_NAME: "sentence-transformers/distiluse-base-multilingual-cased-v1"
          isDownstreamService: true
      - name: Retriever
        data: $response
        internalService:
          serviceName: retriever-svc
          config:
            endpoint: /v1/retrieval
            REDIS_URL: "redis://redis-vector-db.chatqa.svc:6379"
            EMBED_MODEL: "sentence-transformers/distiluse-base-multilingual-cased-v1"
      - name: VectorDB
        internalService:
          serviceName: redis-vector-db
          isDownstreamService: true
      - name: Reranking
        data: $response
        internalService:
          serviceName: reranking-svc
          config:
            endpoint: /v1/reranking
            RERANKING_SERVICE_ENDPOINT: tei-reranking-svc
      - name: TeiReranking
        internalService:
          serviceName: tei-reranking-svc
          config:
            endpoint: /rerank
          isDownstreamService: true
      - name: Llm
        data: $response
        internalService:
          serviceName: llm-svc-1
          config:
            endpoint: /v1/chat/completions
            LLM_MODEL_NAME: "mistralai/Mistral-7B-Instruct-v0.2"
            LLM_MODEL_SERVER: vllm
            LLM_MODEL_SERVER_ENDPOINT: vllm-svc-1
            LLM_DISABLE_STREAMING: "True"
      - name: VLLM
        dependency: Hard
        internalService:
          serviceName: vllm-svc-1
          config:
            endpoint: /v1/completions
            LLM_VLLM_MODEL_NAME: "mistralai/Mistral-7B-Instruct-v0.2"
          isDownstreamService: true
      - name: LanguageDetection
        data: $response
        internalService:
          serviceName: langdtct-svc
          config:
            endpoint: /v1/language_detection
      - name: Llm
        data: $response
        internalService:
          serviceName: llm-svc-2
          config:
            endpoint: /v1/chat/completions
            LLM_MODEL_NAME: "haoranxu/ALMA-13B-R"
            LLM_MODEL_SERVER: vllm
            LLM_MODEL_SERVER_ENDPOINT: vllm-svc-2
            LLM_DISABLE_STREAMING: "False"
      - name: VLLM
        dependency: Hard
        internalService:
          serviceName: vllm-svc-2
          config:
            endpoint: /v1/completions
            LLM_VLLM_MODEL_NAME: "haoranxu/ALMA-13B-R"
          isDownstreamService: true
