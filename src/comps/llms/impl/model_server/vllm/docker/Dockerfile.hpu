# Copyright (C) 2024-2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

FROM vault.habana.ai/gaudi-docker/1.20.0/ubuntu22.04/habanalabs/pytorch-installer-2.6.0:latest

ENV LANG=en_US.UTF-8
RUN pip install --upgrade jinja2==3.1.6

# create user and folders
RUN useradd -u 1000 -m -s /bin/bash user
USER user
ENV PATH="$PATH:/home/user/.local/bin"
WORKDIR /home/user/

ENV VLLM_TARGET_DEVICE="hpu"
# VLLM doesn't share any prebuilt HPU packages (https://docs.vllm.ai/en/latest/getting_started/installation/cpu.html#pre-built-wheels)
# So it is impossible to easily freeze the whole vllm environment with uv
RUN pip install --upgrade pip==25.0.1
RUN pip install --upgrade-strategy eager optimum[habana] --extra-index-url https://download.pytorch.org/whl/cpu
RUN pip install -v git+https://github.com/HabanaAI/vllm-fork.git@v0.6.6.post1+Gaudi-1.20.0 --extra-index-url https://download.pytorch.org/whl/cpu
RUN pip install --upgrade transformers==4.48.0 xgrammar==0.1.18

CMD ["/bin/bash"]
