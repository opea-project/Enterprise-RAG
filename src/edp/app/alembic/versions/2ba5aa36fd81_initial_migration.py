"""Initial migration

Revision ID: 2ba5aa36fd81
Revises: 
Create Date: 2025-08-26 06:46:31.592064

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.engine import reflection

# revision identifiers, used by Alembic.
revision: str = '2ba5aa36fd81'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###

    inspector = reflection.Inspector.from_engine(op.get_bind())
    table_names = inspector.get_table_names()
    if 'files' in table_names:
        columns = [col['name'] for col in inspector.get_columns('files')]
        indexes = [idx['name'] for idx in inspector.get_indexes('files')]
        if 'id' not in columns:
            op.add_column('files', sa.Column('id', sa.UUID(), nullable=False))
        if 'created_at' not in columns:
            op.add_column('files', sa.Column('created_at', sa.DateTime(), nullable=True))
        if 'bucket_name' not in columns:
            op.add_column('files', sa.Column('bucket_name', sa.String(), nullable=True))
        if 'object_name' not in columns:
            op.add_column('files', sa.Column('object_name', sa.String(), nullable=True))
        if 'etag' not in columns:
            op.add_column('files', sa.Column('etag', sa.String(), nullable=True))
        if 'content_type' not in columns:
            op.add_column('files', sa.Column('content_type', sa.String(), nullable=True))
        if 'size' not in columns:
            op.add_column('files', sa.Column('size', sa.Integer(), nullable=True))
        if 'status' not in columns:
            op.add_column('files', sa.Column('status', sa.String(), nullable=True))
        if 'job_name' not in columns:
            op.add_column('files', sa.Column('job_name', sa.String(), nullable=True))
        if 'job_message' not in columns:
            op.add_column('files', sa.Column('job_message', sa.String(), nullable=True))
        if 'chunk_size' not in columns:
            op.add_column('files', sa.Column('chunk_size', sa.Integer(), nullable=True))
        if 'chunks_total' not in columns:
            op.add_column('files', sa.Column('chunks_total', sa.Integer(), nullable=True))
        if 'chunks_processed' not in columns:
            op.add_column('files', sa.Column('chunks_processed', sa.Integer(), nullable=True))
        if 'dataprep_start' not in columns:
            op.add_column('files', sa.Column('dataprep_start', sa.DateTime(), nullable=True))
        if 'dataprep_end' not in columns:
            op.add_column('files', sa.Column('dataprep_end', sa.DateTime(), nullable=True))
        if 'embedding_start' not in columns:
            op.add_column('files', sa.Column('embedding_start', sa.DateTime(), nullable=True))
        if 'embedding_end' not in columns:
            op.add_column('files', sa.Column('embedding_end', sa.DateTime(), nullable=True))
        if 'task_id' not in columns:
            op.add_column('files', sa.Column('task_id', sa.String(), nullable=True))
        if 'marked_for_deletion' not in columns:
            op.add_column('files', sa.Column('marked_for_deletion', sa.Boolean(), nullable=True))
        if 'ix_files_bucket_name' not in indexes:
            op.create_index(op.f('ix_files_bucket_name'), 'files', ['bucket_name'], unique=False)
        if 'ix_files_id' not in indexes:
            op.create_index(op.f('ix_files_id'), 'files', ['id'], unique=False)
        if 'ix_files_object_name' not in indexes:
            op.create_index(op.f('ix_files_object_name'), 'files', ['object_name'], unique=False)
    else:
        op.create_table('files',
        sa.Column('id', sa.UUID(), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=True),
        sa.Column('bucket_name', sa.String(), nullable=True),
        sa.Column('object_name', sa.String(), nullable=True),
        sa.Column('etag', sa.String(), nullable=True),
        sa.Column('content_type', sa.String(), nullable=True),
        sa.Column('size', sa.Integer(), nullable=True),
        sa.Column('status', sa.String(), nullable=True),
        sa.Column('job_name', sa.String(), nullable=True),
        sa.Column('job_message', sa.String(), nullable=True),
        sa.Column('chunk_size', sa.Integer(), nullable=True),
        sa.Column('chunks_total', sa.Integer(), nullable=True),
        sa.Column('chunks_processed', sa.Integer(), nullable=True),
        sa.Column('dataprep_start', sa.DateTime(), nullable=True),
        sa.Column('dataprep_end', sa.DateTime(), nullable=True),
        sa.Column('embedding_start', sa.DateTime(), nullable=True),
        sa.Column('embedding_end', sa.DateTime(), nullable=True),
        sa.Column('task_id', sa.String(), nullable=True),
        sa.Column('marked_for_deletion', sa.Boolean(), nullable=True),
        sa.PrimaryKeyConstraint('id')
        )
        op.create_index(op.f('ix_files_bucket_name'), 'files', ['bucket_name'], unique=False)
        op.create_index(op.f('ix_files_id'), 'files', ['id'], unique=False)
        op.create_index(op.f('ix_files_object_name'), 'files', ['object_name'], unique=False)

    if 'links' in table_names:
        columns = [col['name'] for col in inspector.get_columns('links')]
        indexes = [idx['name'] for idx in inspector.get_indexes('links')]

        if 'id' not in columns:
            op.add_column('links', sa.Column('id', sa.UUID(), nullable=False))
        if 'created_at' not in columns:
            op.add_column('links', sa.Column('created_at', sa.DateTime(), nullable=True))
        if 'uri' not in columns:
            op.add_column('links', sa.Column('uri', sa.String(), nullable=True))
        if 'status' not in columns:
            op.add_column('links', sa.Column('status', sa.String(), nullable=True))
        if 'job_name' not in columns:
            op.add_column('links', sa.Column('job_name', sa.String(), nullable=True))
        if 'job_message' not in columns:
            op.add_column('links', sa.Column('job_message', sa.String(), nullable=True))
        if 'chunk_size' not in columns:
            op.add_column('links', sa.Column('chunk_size', sa.Integer(), nullable=True))
        if 'chunks_total' not in columns:
            op.add_column('links', sa.Column('chunks_total', sa.Integer(), nullable=True))
        if 'chunks_processed' not in columns:
            op.add_column('links', sa.Column('chunks_processed', sa.Integer(), nullable=True))
        if 'dataprep_start' not in columns:
            op.add_column('links', sa.Column('dataprep_start', sa.DateTime(), nullable=True))
        if 'dataprep_end' not in columns:
            op.add_column('links', sa.Column('dataprep_end', sa.DateTime(), nullable=True))
        if 'embedding_start' not in columns:
            op.add_column('links', sa.Column('embedding_start', sa.DateTime(), nullable=True))
        if 'embedding_end' not in columns:
            op.add_column('links', sa.Column('embedding_end', sa.DateTime(), nullable=True))
        if 'task_id' not in columns:
            op.add_column('links', sa.Column('task_id', sa.String(), nullable=True))
        if 'marked_for_deletion' not in columns:
            op.add_column('links', sa.Column('marked_for_deletion', sa.Boolean(), nullable=True))
        if 'ix_links_id' not in indexes:
            op.create_index(op.f('ix_links_id'), 'links', ['id'], unique=False)
        if 'ix_links_uri' not in indexes:
            op.create_index(op.f('ix_links_uri'), 'links', ['uri'], unique=False)
    else:
        op.create_table('links',
        sa.Column('id', sa.UUID(), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=True),
        sa.Column('uri', sa.String(), nullable=True),
        sa.Column('status', sa.String(), nullable=True),
        sa.Column('job_name', sa.String(), nullable=True),
        sa.Column('job_message', sa.String(), nullable=True),
        sa.Column('chunk_size', sa.Integer(), nullable=True),
        sa.Column('chunks_total', sa.Integer(), nullable=True),
        sa.Column('chunks_processed', sa.Integer(), nullable=True),
        sa.Column('dataprep_start', sa.DateTime(), nullable=True),
        sa.Column('dataprep_end', sa.DateTime(), nullable=True),
        sa.Column('embedding_start', sa.DateTime(), nullable=True),
        sa.Column('embedding_end', sa.DateTime(), nullable=True),
        sa.Column('task_id', sa.String(), nullable=True),
        sa.Column('marked_for_deletion', sa.Boolean(), nullable=True),
        sa.PrimaryKeyConstraint('id')
        )
        op.create_index(op.f('ix_links_id'), 'links', ['id'], unique=False)
        op.create_index(op.f('ix_links_uri'), 'links', ['uri'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_links_uri'), table_name='links')
    op.drop_index(op.f('ix_links_id'), table_name='links')
    op.drop_table('links')
    op.drop_index(op.f('ix_files_object_name'), table_name='files')
    op.drop_index(op.f('ix_files_id'), table_name='files')
    op.drop_index(op.f('ix_files_bucket_name'), table_name='files')
    op.drop_table('files')
    # ### end Alembic commands ###
